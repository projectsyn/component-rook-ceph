= Alert rule: CephMgrIsAbsent

include::partial$runbooks/contribution_note.adoc[]

== icon:glasses[] Overview

This alert fires if Prometheus can't scrape metrics from Ceph.
When this alert fires, no alerts regarding Ceph cluster health can fire because the required metrics aren't available.

== icon:bug[] Steps for debugging

=== Check if the MGR pod is running

.Expected cluster state
[source,console]
----
$ ceph_cluster_ns=syn-rook-ceph-cluster
$ kubectl -n "${ceph_cluster}" get pods -l app=rook-ceph-mgr
NAME                               READY   STATUS    RESTARTS   AGE
rook-ceph-mgr-a-564ddc798c-ztvrd   1/1     Running   0          6d1h
----

If the command above doesn't show any pods, verify that the xref:runbooks/RookCephOperatorScaledDown.adoc[Rook-Ceph operator is running].

If the operator is running, check that the `CephCluster` resource is healthy.

include::partial$runbooks/check_cephcluster_resource.adoc[]

=== Check that Prometheus can scrape the MGR pod

If the `kubectl exec` command in the snippet below hangs or otherwise fails, check

* Node to node firewall rules, since we're running Ceph in host network mode
* Network policies between the Prometheus namespace and the Ceph cluster namespace

[source,console]
----
$ ceph_cluster_ns=syn-rook-ceph-cluster
$ mgr_ip=$(kubectl -n "${ceph_cluster_ns}" get pods -l app=rook-ceph-mgr \
      -o jsonpath='{.items[0].status.podIP}')
$ monitoring_ns=openshift-monitoring <1>
$ prometheus_pod=$(kubectl -n ${monitoring_ns} get pods -l app=prometheus \
      -o jsonpath='{.items[0].metadata.name}')
$ kubectl -n "${monitoring_ns}" exec -it "${prometheus_pod}" -- \
      curl "http://${mgr_ip}:9283/metrics"
[ ... metrics output omitted ... ]
----
<1> Replace the namespace depending on your K8s distribution
