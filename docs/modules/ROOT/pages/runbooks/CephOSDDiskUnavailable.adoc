= Alert rule: CephOSDDiskUnavailable

include::partial$runbooks/contribution_note.adoc[]

== icon:glasses[] Overview

This alert fires if an OSD has been removed from the cluster with `ceph osd out` and its associated OSD pod isn't running.

== icon:bug[] Steps for debugging

https://rook.github.io/docs/rook/v1.7/ceph-osd-mgmt.html#remove-an-osd[Official documentation]

Check if the osd is still shown in `osd tree`.
----
$ ceph osd tree
ID   CLASS  WEIGHT   TYPE NAME                     STATUS  REWEIGHT  PRI-AFF
 -1         1.95319  root default
 -5               0      host cluster-data-0zqs7m
 -7         0.48830      host cluster-data-18cmn4
  1    hdd  0.48830          osd.1                     up   1.00000  1.00000
 -3         0.48830      host cluster-data-2twz6w
  2    hdd  0.48830          osd.2                     up   1.00000  1.00000
 -9         0.48830      host cluster-data-3wxznf
  3    hdd  0.48830          osd.3                     up   1.00000  1.00000
-11         0.48830      host cluster-data-4z5nv6
  4    hdd  0.48830          osd.4                     up   1.00000  1.00000
----

In the output above `cluster-data-0zqs7m` is still shown.

You can check the crush map and find that `cluster-data-0zqs7m` is also reported.

Delete it from the crush map.
----
$ ceph osd crush remove cluster-data-0zqs7m
----

