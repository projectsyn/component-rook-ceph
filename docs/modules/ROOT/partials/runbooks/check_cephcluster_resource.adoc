[source,console]
----
$ ceph_cluster_ns=syn-rook-ceph-cluster
$ kubectl -n "${ceph_cluster}" describe cephcluster
[ ... metadata and spec omitted ... ]
Status:
  Ceph:
    Capacity:
      Bytes Available:  574670872576
      Bytes Total:      578156433408
      Bytes Used:       3485560832
      Last Updated:     2022-11-03T13:54:53Z
    Fsid:               a5231b40-1896-448d-aae5-9b37f3d16bee
    Health:             HEALTH_OK <1>
    Last Changed:       2022-11-03T10:31:44Z <2>
    Last Checked:       2022-11-03T13:54:53Z
    Previous Health:    HEALTH_WARN
    Versions:
      Mds:
        ceph version 17.2.5 (98318ae89f1a893a6ded3a640405cdbb33e08757) quincy (stable):  2 <3>
      Mgr:
        ceph version 17.2.5 (98318ae89f1a893a6ded3a640405cdbb33e08757) quincy (stable):  1 <4>
      Mon:
        ceph version 17.2.5 (98318ae89f1a893a6ded3a640405cdbb33e08757) quincy (stable):  3 <5>
      Osd:
        ceph version 17.2.5 (98318ae89f1a893a6ded3a640405cdbb33e08757) quincy (stable):  3 <6>
      Overall:
        ceph version 17.2.5 (98318ae89f1a893a6ded3a640405cdbb33e08757) quincy (stable):  9 <7>
  Conditions:
    Last Heartbeat Time:   2022-11-03T13:54:53Z
    Last Transition Time:  2022-11-02T12:22:41Z
    Message:               Cluster created successfully
    Reason:                ClusterCreated
    Status:                True
    Type:                  Ready <8>
  Message:                 Cluster created successfully
  Observed Generation:     3
  Phase:                   Ready
  State:                   Created
  Storage:
    Device Classes:
      Name:  hdd
  Version:
    Image:    quay.io/ceph/ceph:v17.2.5 <9>
    Version:  17.2.5-0
----
<1> Current Ceph cluster health
<2> Time of last Ceph cluster health status change
<3> List of running Ceph MDS version(s)
<4> List of running Ceph MGR version(s)
<5> List of running Ceph MON version(s)
<6> List of running Ceph OSD version(s)
<7> List of all running Ceph version(s)
<8> Current condition of `CephCluster` resource
<9> Ceph docker image used for the Ceph cluster

If the current condition of the `CephCluster` resource isn't `Ready`, check the Rook-Ceph operator logs for any errors.

[source,console]
----
$ ceph_operator_ns=syn-rook-ceph-operator
$ kubectl -n "${ceph_operator_ns}" logs deploy/rook-ceph-operator --since=2h <1>
----
<1> Adjust parameter `--since` depending on the age of the alert
